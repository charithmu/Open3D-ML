{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "from open3d.ml.datasets import (SemanticKITTI, ParisLille3D, Semantic3D, S3DIS, Toronto3D)\n",
    "from open3d.ml.tf.pipelines import SemanticSegmentation\n",
    "from open3d.ml.tf.models import RandLANet\n",
    "from open3d.ml.utils import Config, get_module\n",
    "\n",
    "import open3d.ml as _ml3d\n",
    "\n",
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import time\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d.ml.tf as ml3d  # or open3d.ml.tf as ml3d\n",
    "\n",
    "# construct a dataset by specifying dataset_path\n",
    "dataset = ml3d.datasets.SemanticKITTI(dataset_path='/home/charith/datasets/semantic-kitti')\n",
    "\n",
    "# get the 'all' split that combines training, validation and test set\n",
    "all_split = dataset.get_split('all')\n",
    "\n",
    "# print the attributes of the first datum\n",
    "print(all_split.get_attr(0))\n",
    "\n",
    "# print the shape of the first point cloud\n",
    "print(all_split.get_data(0)['point'].shape)\n",
    "\n",
    "# show the first 100 frames using the visualizer\n",
    "vis = ml3d.vis.Visualizer()\n",
    "vis.visualize_dataset(dataset, 'all', indices=range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = S3DIS(\"/home/charith/datasets/S3DIS/\", use_cache=True)\n",
    "\n",
    "model = RandLANet(dim_input=6, dim_feature=8)\n",
    "\n",
    "pipeline = SemanticSegmentation(model=model, dataset=dataset, max_epoch=100)\n",
    "\n",
    "\n",
    "with open('scripts/README.md', 'r') as f:\n",
    "    readme = f.read()\n",
    "\n",
    "pipeline.cfg_tb = {\n",
    "    'readme': readme,\n",
    "    'cmd_line': ' '.join(sys.argv[:]),\n",
    "    'dataset': pprint.pformat(\"S3DIS\", indent=2),\n",
    "    'model': pprint.pformat(\"RandLANet\", indent=2),\n",
    "    'pipeline': pprint.pformat(\"SemanticSegmentation\", indent=2)\n",
    "}\n",
    "\n",
    "pipeline.run_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-interest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Inference and test example\n",
    "    from open3d.ml.tf.pipelines import SemanticSegmentation\n",
    "    from open3d.ml.tf.models import RandLANet\n",
    "\n",
    "    Pipeline = get_module(\"pipeline\", \"SemanticSegmentation\", \"tf\")\n",
    "    Model = get_module(\"model\", \"RandLANet\", \"tf\")\n",
    "    Dataset = get_module(\"dataset\", \"SemanticKITTI\")\n",
    "\n",
    "    RandLANet = Model(ckpt_path=args.path_ckpt_randlanet)\n",
    "\n",
    "    # Initialize by specifying config file path\n",
    "    SemanticKITTI = Dataset(args.path_semantickitti, use_cache=False)\n",
    "\n",
    "    pipeline = Pipeline(model=RandLANet, dataset=SemanticKITTI)\n",
    "\n",
    "    # inference\n",
    "    # get data\n",
    "    train_split = SemanticKITTI.get_split(\"train\")\n",
    "    data = train_split.get_data(0)\n",
    "    # restore weights\n",
    "\n",
    "    # run inference\n",
    "    results = pipeline.run_inference(data)\n",
    "    print(results)\n",
    "\n",
    "    # test\n",
    "    pipeline.run_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}