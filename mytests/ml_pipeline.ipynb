{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hollow-supervision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using external Open3D-ML in /home/threedee/repos/Open3D-ML\n",
      "{'cfg_file': '/home/threedee/repos/Open3D-ML/ml3d/configs/randlanet_smartlab.yml',\n",
      " 'ckpt_path': None,\n",
      " 'dataset_path': '/home/threedee/datasets/SmartLab',\n",
      " 'device': 'cuda',\n",
      " 'framework': 'tf',\n",
      " 'split': 'train'}\n"
     ]
    }
   ],
   "source": [
    "basedir = \"/home/threedee/repos/Open3D-ML\"\n",
    "datesetbase = \"/home/threedee/datasets\"\n",
    "\n",
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import os.path as osp\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"OPEN3D_ML_ROOT\"] = basedir\n",
    "\n",
    "import open3d.ml as _ml3d\n",
    "\n",
    "randlanet_semantickitti_cfg = basedir + \"/ml3d/configs/randlanet_semantickitti.yml\"\n",
    "randlanet_s3dis_cfg = basedir + \"/ml3d/configs/randlanet_s3dis.yml\"\n",
    "\n",
    "randlanet_smartlab_cfg = basedir + \"/ml3d/configs/randlanet_smartlab.yml\"\n",
    "kpconv_smartlab_cfg = basedir + \"/ml3d/configs/kpconv_smartlab.yml\"\n",
    "\n",
    "ckpt_path = basedir + \"/logs/RandLANet_SmartLab_tf/checkpoint/ckpt-14\"\n",
    "\n",
    "kwargs = {\n",
    "    \"framework\": \"tf\",\n",
    "    \"device\": \"cuda\",\n",
    "    \"dataset_path\": datesetbase + \"/SmartLab\",\n",
    "    \"split\": \"train\",\n",
    "    \"ckpt_path\": None,\n",
    "    \"cfg_file\": randlanet_smartlab_cfg,\n",
    "}\n",
    "\n",
    "args = type(\"args\", (object,), kwargs)()\n",
    "\n",
    "pprint.pprint(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "australian-devil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "if args.framework == \"torch\":\n",
    "    import open3d.ml.torch as ml3d\n",
    "else:\n",
    "    import open3d.ml.tf as ml3d\n",
    "    import tensorflow as tf\n",
    "\n",
    "\n",
    "def merge_cfg_file(cfg, args, extra_dict):\n",
    "    if args.device is not None:\n",
    "        cfg.pipeline.device = args.device\n",
    "        cfg.model.device = args.device\n",
    "    if args.split is not None:\n",
    "        cfg.pipeline.split = args.split\n",
    "    if args.dataset_path is not None:\n",
    "        cfg.dataset.dataset_path = args.dataset_path\n",
    "    if args.ckpt_path is not None:\n",
    "        cfg.model.ckpt_path = args.ckpt_path\n",
    "\n",
    "    return cfg.dataset, cfg.pipeline, cfg.model\n",
    "\n",
    "\n",
    "device = args.device\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "print(gpus)\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        if device == \"cpu\":\n",
    "            tf.config.set_visible_devices([], \"GPU\")\n",
    "        elif device == \"cuda\":\n",
    "            tf.config.set_visible_devices(gpus[0], \"GPU\")\n",
    "        else:\n",
    "            idx = device.split(\":\")[1]\n",
    "            tf.config.set_visible_devices(gpus[int(idx)], \"GPU\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "cfg = _ml3d.utils.Config.load_from_file(args.cfg_file)\n",
    "\n",
    "Pipeline = _ml3d.utils.get_module(\"pipeline\", cfg.pipeline.name, args.framework)\n",
    "Model = _ml3d.utils.get_module(\"model\", cfg.model.name, args.framework)\n",
    "Dataset = _ml3d.utils.get_module(\"dataset\", cfg.dataset.name)\n",
    "\n",
    "cfg_dataset, cfg_pipeline, cfg_model = merge_cfg_file(cfg, args, None)\n",
    "\n",
    "dataset = Dataset(**cfg_dataset)\n",
    "model = Model(**cfg_model)\n",
    "pipeline = Pipeline(model, dataset, **cfg_pipeline)\n",
    "\n",
    "Unlabeled = [231, 87, 36]\n",
    "Floor = [188, 169, 26]\n",
    "Wall = [100, 244, 245]\n",
    "Robot = [150, 30, 140]\n",
    "Human = [0, 248, 26]\n",
    "AGV = [18, 35, 243]\n",
    "\n",
    "colors = {\n",
    "    \"Unlabeled\": [x / 255.0 for x in Unlabeled],\n",
    "    \"Floor\": [x / 255.0 for x in Floor],\n",
    "    \"Wall\": [x / 255.0 for x in Wall],\n",
    "    \"Robot\": [x / 255.0 for x in Robot],\n",
    "    \"Human\": [x / 255.0 for x in Human],\n",
    "    \"AGV\": [x / 255.0 for x in AGV],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-retention",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = ml3d.vis.Visualizer()\n",
    "lut = ml3d.vis.LabelLUT()\n",
    "\n",
    "pprint.pprint(colors)\n",
    "i = 0\n",
    "for key, val in colors.items():\n",
    "    lut.add_label(key, i, val)\n",
    "    i = i + 1\n",
    "\n",
    "vis.visualize_dataset(dataset, \"test\", lut, width=2100, height=1600)  # , indices=range(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-application",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-03-24 01:09:10,354 - semantic_segmentation - <ml3d.tf.models.randlanet.RandLANet object at 0x7f8ea82cf0a0>\n",
      "INFO - 2021-03-24 01:09:10,354 - semantic_segmentation - Logging in file : logs/RandLANet_SmartLab_tf/log_train_2021-03-24_01:09:10.txt\n",
      "INFO - 2021-03-24 01:09:10,355 - smartlab - Found 152 pointclouds for training\n",
      "INFO - 2021-03-24 01:09:10,508 - smartlab - Found 44 pointclouds for validation\n",
      "INFO - 2021-03-24 01:09:10,573 - semantic_segmentation - Writing summary in train_log/00003_RandLANet_SmartLab_tf.\n",
      "INFO - 2021-03-24 01:09:10,588 - semantic_segmentation - Restored from logs/RandLANet_SmartLab_tf/checkpoint/ckpt-14\n",
      "INFO - 2021-03-24 01:09:10,588 - semantic_segmentation - === EPOCH 0/100 ===\n",
      "training: 100%|██████████| 76/76 [00:56<00:00,  1.35it/s]\n",
      "validation: 100%|██████████| 15/15 [00:06<00:00,  2.17it/s]\n",
      "INFO - 2021-03-24 01:10:13,785 - semantic_segmentation - loss train: 1.051  eval: 1.164\n",
      "INFO - 2021-03-24 01:10:13,786 - semantic_segmentation - acc train: 0.947  eval: 0.933\n",
      "INFO - 2021-03-24 01:10:13,786 - semantic_segmentation - iou train: 0.861  eval: 0.883\n",
      "INFO - 2021-03-24 01:10:13,948 - semantic_segmentation - Saved checkpoint at: logs/RandLANet_SmartLab_tf/checkpoint/ckpt-15\n",
      "INFO - 2021-03-24 01:10:13,948 - semantic_segmentation - === EPOCH 1/100 ===\n",
      "training: 100%|██████████| 76/76 [00:56<00:00,  1.35it/s]\n",
      "validation: 100%|██████████| 15/15 [00:06<00:00,  2.18it/s]\n",
      "INFO - 2021-03-24 01:11:17,132 - semantic_segmentation - loss train: 0.484  eval: 0.498\n",
      "INFO - 2021-03-24 01:11:17,133 - semantic_segmentation - acc train: 0.976  eval: 0.962\n",
      "INFO - 2021-03-24 01:11:17,133 - semantic_segmentation - iou train: 0.908  eval: 0.942\n",
      "INFO - 2021-03-24 01:11:17,137 - semantic_segmentation - === EPOCH 2/100 ===\n",
      "training: 100%|██████████| 76/76 [00:58<00:00,  1.30it/s]\n",
      "validation: 100%|██████████| 15/15 [00:06<00:00,  2.19it/s]\n",
      "INFO - 2021-03-24 01:12:22,352 - semantic_segmentation - loss train: 0.815  eval: 1.209\n",
      "INFO - 2021-03-24 01:12:22,353 - semantic_segmentation - acc train: 0.945  eval: 0.921\n",
      "INFO - 2021-03-24 01:12:22,353 - semantic_segmentation - iou train: 0.868  eval: 0.870\n",
      "INFO - 2021-03-24 01:12:22,358 - semantic_segmentation - === EPOCH 3/100 ===\n",
      "training: 100%|██████████| 76/76 [00:57<00:00,  1.32it/s]\n",
      "validation: 100%|██████████| 15/15 [00:07<00:00,  2.08it/s]\n",
      "INFO - 2021-03-24 01:13:27,092 - semantic_segmentation - loss train: 0.431  eval: 0.315\n",
      "INFO - 2021-03-24 01:13:27,093 - semantic_segmentation - acc train: 0.979  eval: 0.977\n",
      "INFO - 2021-03-24 01:13:27,093 - semantic_segmentation - iou train: 0.915  eval: 0.962\n",
      "INFO - 2021-03-24 01:13:27,096 - semantic_segmentation - === EPOCH 4/100 ===\n",
      "training: 100%|██████████| 76/76 [00:59<00:00,  1.29it/s]\n",
      "validation: 100%|██████████| 15/15 [00:07<00:00,  1.96it/s]\n",
      "INFO - 2021-03-24 01:14:33,790 - semantic_segmentation - loss train: 0.492  eval: 0.359\n",
      "INFO - 2021-03-24 01:14:33,790 - semantic_segmentation - acc train: 0.974  eval: 0.968\n",
      "INFO - 2021-03-24 01:14:33,791 - semantic_segmentation - iou train: 0.909  eval: 0.923\n",
      "INFO - 2021-03-24 01:14:33,793 - semantic_segmentation - === EPOCH 5/100 ===\n",
      "training: 100%|██████████| 76/76 [00:59<00:00,  1.27it/s]\n",
      "validation: 100%|██████████| 15/15 [00:06<00:00,  2.18it/s]\n",
      "INFO - 2021-03-24 01:15:40,669 - semantic_segmentation - loss train: 0.457  eval: 1.264\n",
      "INFO - 2021-03-24 01:15:40,669 - semantic_segmentation - acc train: 0.975  eval: 0.923\n",
      "INFO - 2021-03-24 01:15:40,670 - semantic_segmentation - iou train: 0.909  eval: 0.856\n",
      "INFO - 2021-03-24 01:15:40,673 - semantic_segmentation - === EPOCH 6/100 ===\n",
      "training: 100%|██████████| 76/76 [00:57<00:00,  1.31it/s]\n",
      "validation: 100%|██████████| 15/15 [00:07<00:00,  2.14it/s]\n",
      "INFO - 2021-03-24 01:16:45,542 - semantic_segmentation - loss train: 0.380  eval: 0.358\n",
      "INFO - 2021-03-24 01:16:45,542 - semantic_segmentation - acc train: 0.981  eval: 0.975\n",
      "INFO - 2021-03-24 01:16:45,543 - semantic_segmentation - iou train: 0.920  eval: 0.945\n",
      "INFO - 2021-03-24 01:16:45,547 - semantic_segmentation - === EPOCH 7/100 ===\n",
      "training:  47%|████▋     | 36/76 [00:28<00:30,  1.32it/s]"
     ]
    }
   ],
   "source": [
    "pipeline.cfg_tb = {\n",
    "    \"readme\": \"readme\",\n",
    "    \"cmd_line\": \"cmd_line\",\n",
    "    \"dataset\": pprint.pformat(cfg_dataset, indent=2),\n",
    "    \"model\": pprint.pformat(cfg_model, indent=2),\n",
    "    \"pipeline\": pprint.pformat(cfg_pipeline, indent=2),\n",
    "}\n",
    "# print(pipeline.cfg_tb)\n",
    "\n",
    "if args.split == \"test\":\n",
    "    pipeline.run_test()\n",
    "else:\n",
    "    pipeline.run_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.load_ckpt(ckpt_path=ckpt_path)\n",
    "# pipeline.run_test()\n",
    "\n",
    "# data = test_split.get_data(0)\n",
    "# attr = test_split.get_attr(0)\n",
    "# print(attr)\n",
    "\n",
    "# results = pipeline.run_inference(data)\n",
    "\n",
    "# pred = (results['predict_labels']).astype(np.int32)\n",
    "# scores = results['predict_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = dataset.get_split(\"test\")\n",
    "\n",
    "vis_points = []\n",
    "times = []\n",
    "\n",
    "for idx in range(len(test_split)):\n",
    "\n",
    "    st = time.perf_counter()\n",
    "    attr = test_split.get_attr(idx)\n",
    "    data = test_split.get_data(idx)\n",
    "\n",
    "    print(attr)\n",
    "    results = pipeline.run_inference(data)\n",
    "\n",
    "    pred = (results[\"predict_labels\"]).astype(np.int32)\n",
    "\n",
    "    label = data[\"label\"]\n",
    "    pts = data[\"point\"]\n",
    "\n",
    "    vis_d = {\n",
    "        \"name\": attr[\"name\"],\n",
    "        \"points\": pts,\n",
    "        \"labels\": label,\n",
    "        \"pred\": pred,\n",
    "    }\n",
    "\n",
    "    vis_points.append(vis_d)\n",
    "    et = time.perf_counter()\n",
    "    times.append(et - st)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(times)\n",
    "print(f\"Average time {np.mean(times):0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = ml3d.vis.Visualizer()\n",
    "lut = ml3d.vis.LabelLUT()\n",
    "\n",
    "pprint.pprint(colors)\n",
    "\n",
    "label_names = dataset.get_label_to_names()\n",
    "pprint.pprint(label_names)\n",
    "\n",
    "for (c, cv), (l, lv) in zip(colors.items(), label_names.items()):\n",
    "    lut.add_label(lv, l, cv)\n",
    "\n",
    "v.set_lut(\"labels\", lut)\n",
    "v.set_lut(\"pred\", lut)\n",
    "\n",
    "v.visualize(vis_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = dataset.get_split(\"test\")\n",
    "\n",
    "for idx in range(len(test_split)):\n",
    "    attr = test_split.get_attr(idx)\n",
    "    data = test_split.get_data(idx)\n",
    "\n",
    "    unique, counts = np.unique(data[\"label\"], return_counts=True)\n",
    "    print(np.asarray((unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-vault",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
