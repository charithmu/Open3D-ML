{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collectible-roulette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using external Open3D-ML in /home/lidar/dev/Open3D-ML\n",
      "{'cfg_file': '/home/lidar/dev/Open3D-ML/ml3d/configs/randlanet_smartlab.yml',\n",
      " 'ckpt_path': 'logs/RandLANet_SmartLab_tf/checkpoint/ckpt-6',\n",
      " 'dataset_path': '/home/lidar/datasets/SmartLab',\n",
      " 'device': 'cuda',\n",
      " 'framework': 'tf',\n",
      " 'split': 'test'}\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import os.path as osp\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "homedir = str(Path.home())\n",
    "\n",
    "basedir = homedir + \"/dev/Open3D-ML\"\n",
    "datesetbase = homedir + \"/datasets\"\n",
    "\n",
    "os.environ[\"OPEN3D_ML_ROOT\"] = basedir\n",
    "\n",
    "import open3d.ml as _ml3d\n",
    "\n",
    "randlanet_semantickitti_cfg = basedir + \"/ml3d/configs/randlanet_semantickitti.yml\"\n",
    "randlanet_s3dis_cfg = basedir + \"/ml3d/configs/randlanet_s3dis.yml\"\n",
    "\n",
    "randlanet_smartlab_cfg = basedir + \"/ml3d/configs/randlanet_smartlab.yml\"\n",
    "kpconv_smartlab_cfg = basedir + \"/ml3d/configs/kpconv_smartlab.yml\"\n",
    "\n",
    "# checkpoints\n",
    "smartlab1 = basedir + \"/mytests/logs/RandLANet_SmartLab_tf/checkpoint/ckpt-6\"\n",
    "\n",
    "s3dis1 = basedir + \"/final-chechpoints/randlanet_s3dis_tf/checkpoint/ckpt-91\"\n",
    "s3dis2 = basedir + \"/final-checkpoints/RandLANet_S3DIS_tf/checkpoint/ckpt-6\"\n",
    "\n",
    "\n",
    "kwargs = {\n",
    "    \"framework\": \"tf\",\n",
    "    \"device\": \"cuda\",\n",
    "    \"dataset_path\": datesetbase + \"/SmartLab\",\n",
    "    \"split\": \"test\",\n",
    "    \"ckpt_path\": \"logs/RandLANet_SmartLab_tf/checkpoint/ckpt-6\",\n",
    "    \"cfg_file\": randlanet_smartlab_cfg,\n",
    "}\n",
    "\n",
    "args = type(\"args\", (object,), kwargs)()\n",
    "\n",
    "pprint.pprint(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wooden-discussion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "if args.framework == \"torch\":\n",
    "    import open3d.ml.torch as ml3d\n",
    "else:\n",
    "    import open3d.ml.tf as ml3d\n",
    "    import tensorflow as tf\n",
    "\n",
    "\n",
    "def merge_cfg_file(cfg, args, extra_dict):\n",
    "    if args.device is not None:\n",
    "        cfg.pipeline.device = args.device\n",
    "        cfg.model.device = args.device\n",
    "    if args.split is not None:\n",
    "        cfg.pipeline.split = args.split\n",
    "    if args.dataset_path is not None:\n",
    "        cfg.dataset.dataset_path = args.dataset_path\n",
    "    if args.ckpt_path is not None:\n",
    "        cfg.model.ckpt_path = args.ckpt_path\n",
    "\n",
    "    return cfg.dataset, cfg.pipeline, cfg.model\n",
    "\n",
    "\n",
    "device = args.device\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "print(gpus)\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        if device == \"cpu\":\n",
    "            tf.config.set_visible_devices([], \"GPU\")\n",
    "        elif device == \"cuda\":\n",
    "            tf.config.set_visible_devices(gpus[0], \"GPU\")\n",
    "        else:\n",
    "            idx = device.split(\":\")[1]\n",
    "            tf.config.set_visible_devices(gpus[int(idx)], \"GPU\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "cfg = _ml3d.utils.Config.load_from_file(args.cfg_file)\n",
    "\n",
    "cfg.dataset[\"dataset_path\"] = args.dataset_path\n",
    "\n",
    "Pipeline = _ml3d.utils.get_module(\"pipeline\", cfg.pipeline.name, args.framework)\n",
    "Model = _ml3d.utils.get_module(\"model\", cfg.model.name, args.framework)\n",
    "Dataset = _ml3d.utils.get_module(\"dataset\", cfg.dataset.name)\n",
    "\n",
    "cfg_dataset, cfg_pipeline, cfg_model = merge_cfg_file(cfg, args, None)\n",
    "\n",
    "dataset = Dataset(**cfg_dataset)\n",
    "model = Model(**cfg_model)\n",
    "pipeline = Pipeline(model, dataset, **cfg_pipeline)\n",
    "\n",
    "Unlabeled = [231, 87, 36]\n",
    "Floor = [188, 169, 26]\n",
    "Wall = [100, 244, 245]\n",
    "Robot = [150, 30, 140]\n",
    "Human = [0, 248, 26]\n",
    "AGV = [18, 35, 243]\n",
    "\n",
    "colors = {\n",
    "    \"Unlabeled\": [x / 255.0 for x in Unlabeled],\n",
    "    \"Floor\": [x / 255.0 for x in Floor],\n",
    "    \"Wall\": [x / 255.0 for x in Wall],\n",
    "    \"Robot\": [x / 255.0 for x in Robot],\n",
    "    \"Human\": [x / 255.0 for x in Human],\n",
    "    \"AGV\": [x / 255.0 for x in AGV],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = ml3d.vis.Visualizer()\n",
    "lut = ml3d.vis.LabelLUT()\n",
    "\n",
    "pprint.pprint(colors)\n",
    "i = 0\n",
    "for key, val in colors.items():\n",
    "    lut.add_label(key, i, val)\n",
    "    i = i + 1\n",
    "\n",
    "# vis.visualize_dataset(dataset, \"train\", width=2100, height=1600)  # , indices=range(100)\n",
    "vis.visualize_dataset(dataset, \"train\", lut, width=2100, height=1600)  # , indices=range(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dominican-interstate",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-03-28 20:04:54,592 - semantic_segmentation - Restored from logs/RandLANet_SmartLab_tf/checkpoint/ckpt-6\n",
      "INFO - 2021-03-28 20:04:54,593 - semantic_segmentation - Logging in file : logs/RandLANet_SmartLab_tf/log_test_2021-03-28_20:04:54.txt\n",
      "INFO - 2021-03-28 20:04:54,594 - semantic_segmentation - Started testing\n",
      "INFO - 2021-03-28 20:04:54,595 - smartlab - Found 22 pointclouds for test\n",
      "test:   0%|          | 0/22 [00:00<?, ?it/s]INFO - 2021-03-28 20:04:54,600 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/20596 [00:00<?, ?it/s]\u001b[AWARNING - 2021-03-28 20:04:57,202 - deprecation - From %s: %s (from %s) is deprecated and will be removed %s.\n",
      "Instructions for updating:\n",
      "%s\n",
      "\n",
      " 58%|█████▊    | 11909/20596 [00:02<00:01, 4656.66it/s]\u001b[A\n",
      "100%|██████████| 20596/20596 [00:03<00:00, 5442.55it/s]\u001b[A\n",
      "test:   5%|▍         | 1/22 [00:03<01:22,  3.95s/it]INFO - 2021-03-28 20:04:58,546 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/20228 [00:00<?, ?it/s]\u001b[A\n",
      " 56%|█████▋    | 11380/20228 [00:00<00:00, 19399.39it/s]\u001b[A\n",
      "100%|██████████| 20228/20228 [00:01<00:00, 17097.85it/s]\u001b[A\n",
      "test:   9%|▉         | 2/22 [00:05<00:47,  2.40s/it]INFO - 2021-03-28 20:04:59,857 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/20529 [00:00<?, ?it/s]\u001b[A\n",
      " 48%|████▊     | 9813/20529 [00:00<00:00, 15614.18it/s]\u001b[A\n",
      " 88%|████████▊ | 18138/20529 [00:01<00:00, 15231.14it/s]\u001b[A\n",
      "100%|██████████| 20529/20529 [00:01<00:00, 11574.16it/s]\u001b[A\n",
      "test:  14%|█▎        | 3/22 [00:07<00:41,  2.16s/it]INFO - 2021-03-28 20:05:01,745 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/20285 [00:00<?, ?it/s]\u001b[A\n",
      " 56%|█████▌    | 11400/20285 [00:00<00:00, 18746.69it/s]\u001b[A\n",
      "100%|██████████| 20285/20285 [00:01<00:00, 11617.48it/s]\u001b[A\n",
      "test:  18%|█▊        | 4/22 [00:09<00:36,  2.05s/it]INFO - 2021-03-28 20:05:03,611 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/19824 [00:00<?, ?it/s]\u001b[A\n",
      " 53%|█████▎    | 10440/19824 [00:00<00:00, 17878.95it/s]\u001b[A\n",
      "100%|██████████| 19824/19824 [00:01<00:00, 11298.98it/s]\u001b[A\n",
      "test:  23%|██▎       | 5/22 [00:10<00:33,  1.99s/it]INFO - 2021-03-28 20:05:05,498 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/20223 [00:00<?, ?it/s]\u001b[A\n",
      " 51%|█████     | 10361/20223 [00:00<00:00, 17305.27it/s]\u001b[A\n",
      "100%|██████████| 20223/20223 [00:01<00:00, 11021.56it/s]\u001b[A\n",
      "test:  27%|██▋       | 6/22 [00:12<00:31,  1.98s/it]INFO - 2021-03-28 20:05:07,457 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/20495 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 10248/20495 [00:00<00:00, 17507.11it/s]\u001b[A\n",
      "100%|██████████| 20495/20495 [00:01<00:00, 11411.53it/s]\u001b[A\n",
      "test:  32%|███▏      | 7/22 [00:14<00:29,  1.95s/it]INFO - 2021-03-28 20:05:09,361 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/21127 [00:00<?, ?it/s]\u001b[A\n",
      " 54%|█████▍    | 11454/21127 [00:00<00:00, 21875.45it/s]\u001b[A\n",
      "100%|██████████| 21127/21127 [00:01<00:00, 11826.00it/s]\u001b[A\n",
      "test:  36%|███▋      | 8/22 [00:16<00:27,  1.94s/it]INFO - 2021-03-28 20:05:11,262 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/20169 [00:00<?, ?it/s]\u001b[A\n",
      " 56%|█████▌    | 11321/20169 [00:00<00:00, 18864.82it/s]\u001b[A\n",
      "100%|██████████| 20169/20169 [00:01<00:00, 10340.47it/s]\u001b[A\n",
      "test:  41%|████      | 9/22 [00:18<00:25,  1.98s/it]INFO - 2021-03-28 20:05:13,326 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/21011 [00:00<?, ?it/s]\u001b[A\n",
      " 45%|████▌     | 9537/21011 [00:00<00:00, 17595.46it/s]\u001b[A\n",
      "100%|██████████| 21011/21011 [00:01<00:00, 12219.37it/s]\u001b[A\n",
      "test:  45%|████▌     | 10/22 [00:20<00:23,  1.93s/it]INFO - 2021-03-28 20:05:15,161 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/20259 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 10156/20259 [00:00<00:00, 16942.98it/s]\u001b[A\n",
      "100%|██████████| 20259/20259 [00:02<00:00, 8619.58it/s] \u001b[A\n",
      "test:  50%|█████     | 11/22 [00:23<00:23,  2.10s/it]INFO - 2021-03-28 20:05:17,643 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/20708 [00:00<?, ?it/s]\u001b[A\n",
      " 56%|█████▌    | 11515/20708 [00:00<00:00, 20387.86it/s]\u001b[A\n",
      "100%|██████████| 20708/20708 [00:02<00:00, 10346.95it/s]\u001b[A\n",
      "test:  55%|█████▍    | 12/22 [00:25<00:21,  2.11s/it]INFO - 2021-03-28 20:05:19,769 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/20292 [00:00<?, ?it/s]\u001b[A\n",
      " 58%|█████▊    | 11760/20292 [00:00<00:00, 14956.75it/s]\u001b[A\n",
      "100%|██████████| 20292/20292 [00:02<00:00, 9414.93it/s] \u001b[A\n",
      "test:  59%|█████▉    | 13/22 [00:27<00:19,  2.16s/it]INFO - 2021-03-28 20:05:22,039 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/20292 [00:00<?, ?it/s]\u001b[A\n",
      " 58%|█████▊    | 11767/20292 [00:00<00:00, 20973.07it/s]\u001b[A\n",
      "100%|██████████| 20292/20292 [00:01<00:00, 17336.75it/s]\u001b[A\n",
      "test:  64%|██████▎   | 14/22 [00:28<00:15,  1.89s/it]INFO - 2021-03-28 20:05:23,327 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/20319 [00:00<?, ?it/s]\u001b[A\n",
      " 45%|████▍     | 9067/20319 [00:00<00:01, 9158.18it/s]\u001b[A\n",
      " 90%|████████▉ | 18196/20319 [00:01<00:00, 11627.93it/s]\u001b[A\n",
      "100%|██████████| 20319/20319 [00:02<00:00, 9120.55it/s] \u001b[A\n",
      "test:  68%|██████▊   | 15/22 [00:31<00:14,  2.03s/it]INFO - 2021-03-28 20:05:25,686 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/20417 [00:00<?, ?it/s]\u001b[A\n",
      " 57%|█████▋    | 11580/20417 [00:00<00:00, 20585.10it/s]\u001b[A\n",
      "100%|██████████| 20417/20417 [00:01<00:00, 17411.08it/s]\u001b[A\n",
      "test:  73%|███████▎  | 16/22 [00:32<00:10,  1.81s/it]INFO - 2021-03-28 20:05:26,975 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/20131 [00:00<?, ?it/s]\u001b[A\n",
      " 45%|████▌     | 9132/20131 [00:01<00:01, 9058.35it/s]\u001b[A\n",
      "100%|██████████| 20131/20131 [00:02<00:00, 6814.44it/s] \u001b[A\n",
      "test:  77%|███████▋  | 17/22 [00:35<00:10,  2.19s/it]INFO - 2021-03-28 20:05:30,050 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/20885 [00:00<?, ?it/s]\u001b[A\n",
      " 41%|████      | 8587/20885 [00:00<00:01, 11032.08it/s]\u001b[A\n",
      "100%|██████████| 20885/20885 [00:02<00:00, 8114.54it/s] \u001b[A\n",
      "test:  82%|████████▏ | 18/22 [00:38<00:09,  2.34s/it]INFO - 2021-03-28 20:05:32,745 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/19793 [00:00<?, ?it/s]\u001b[A\n",
      " 66%|██████▌   | 13024/19793 [00:00<00:00, 20417.05it/s]\u001b[A\n",
      "100%|██████████| 19793/19793 [00:02<00:00, 7980.77it/s] \u001b[A\n",
      "test:  86%|████████▋ | 19/22 [00:40<00:07,  2.43s/it]INFO - 2021-03-28 20:05:35,365 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/20362 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 10206/20362 [00:00<00:00, 17410.62it/s]\u001b[A\n",
      "100%|██████████| 20362/20362 [00:02<00:00, 9927.82it/s] \u001b[A\n",
      "test:  91%|█████████ | 20/22 [00:42<00:04,  2.36s/it]INFO - 2021-03-28 20:05:37,565 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/20892 [00:00<?, ?it/s]\u001b[A\n",
      " 40%|███▉      | 8271/20892 [00:00<00:01, 12417.77it/s]\u001b[A\n",
      "100%|██████████| 20892/20892 [00:01<00:00, 12105.81it/s]\u001b[A\n",
      "test:  95%|█████████▌| 21/22 [00:44<00:02,  2.21s/it]INFO - 2021-03-28 20:05:39,415 - semantic_segmentation - running inference\n",
      "\n",
      "  0%|          | 0/20312 [00:00<?, ?it/s]\u001b[A\n",
      " 55%|█████▍    | 11102/20312 [00:00<00:00, 17823.13it/s]\u001b[A\n",
      "100%|██████████| 20312/20312 [00:01<00:00, 17284.02it/s]\u001b[A\n",
      "test: 100%|██████████| 22/22 [00:46<00:00,  2.10s/it]\n",
      "INFO - 2021-03-28 20:05:40,719 - semantic_segmentation - Per class Accuracy : [0.97193171 0.9852328  0.98136753 0.97589184 0.77029038 0.98399749]\n",
      "INFO - 2021-03-28 20:05:40,720 - semantic_segmentation - Per class IOUs : [0.95914877 0.92916891 0.96117431 0.91954307 0.76299984 0.94939529]\n",
      "INFO - 2021-03-28 20:05:40,720 - semantic_segmentation - Overall Accuracy : 0.958\n",
      "INFO - 2021-03-28 20:05:40,721 - semantic_segmentation - Overall IOU : 0.925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97193171 0.9852328  0.98136753 0.97589184 0.77029038 0.98399749\n",
      " 0.95760686]\n",
      "[0.95914877 0.92916891 0.96117431 0.91954307 0.76299984 0.94939529\n",
      " 0.92453161]\n"
     ]
    }
   ],
   "source": [
    "pipeline.cfg_tb = {\n",
    "    \"readme\": \"readme\",\n",
    "    \"cmd_line\": \"cmd_line\",\n",
    "    \"dataset\": pprint.pformat(cfg_dataset, indent=2),\n",
    "    \"model\": pprint.pformat(cfg_model, indent=2),\n",
    "    \"pipeline\": pprint.pformat(cfg_pipeline, indent=2),\n",
    "}\n",
    "# print(pipeline.cfg_tb)\n",
    "\n",
    "if args.split == \"test\":\n",
    "    pipeline.run_test()\n",
    "else:\n",
    "    pipeline.run_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.load_ckpt(ckpt_path=ckpt_path)\n",
    "# pipeline.run_test()\n",
    "\n",
    "# data = test_split.get_data(0)\n",
    "# attr = test_split.get_attr(0)\n",
    "# print(attr)\n",
    "\n",
    "# results = pipeline.run_inference(data)\n",
    "\n",
    "# pred = (results['predict_labels']).astype(np.int32)\n",
    "# scores = results['predict_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lonely-training",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-03-28 20:06:28,800 - smartlab - Found 22 pointclouds for test\n",
      "INFO - 2021-03-28 20:06:28,806 - semantic_segmentation - running inference\n",
      "  0%|          | 0/20596 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'pcd-1615489278347081000', 'path': '/home/lidar/datasets/SmartLab/test/pcd-1615489278347081000.npy', 'split': 'test'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20596/20596 [00:01<00:00, 11566.37it/s]\n",
      "INFO - 2021-03-28 20:06:30,716 - semantic_segmentation - running inference\n",
      "  0%|          | 0/20228 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'pcd-1615483731179918000', 'path': '/home/lidar/datasets/SmartLab/test/pcd-1615483731179918000.npy', 'split': 'test'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20228/20228 [00:01<00:00, 18816.08it/s]\n",
      "INFO - 2021-03-28 20:06:31,897 - semantic_segmentation - running inference\n",
      "  0%|          | 0/20529 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'pcd-1615483727027118000', 'path': '/home/lidar/datasets/SmartLab/test/pcd-1615483727027118000.npy', 'split': 'test'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20529/20529 [00:01<00:00, 17992.31it/s]\n",
      "INFO - 2021-03-28 20:06:33,169 - semantic_segmentation - running inference\n",
      "  0%|          | 0/20285 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'pcd-1615484675696102000', 'path': '/home/lidar/datasets/SmartLab/test/pcd-1615484675696102000.npy', 'split': 'test'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20285/20285 [00:01<00:00, 18051.66it/s]\n",
      "INFO - 2021-03-28 20:06:34,398 - semantic_segmentation - running inference\n",
      "  0%|          | 0/19824 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'pcd-1615483739343909000', 'path': '/home/lidar/datasets/SmartLab/test/pcd-1615483739343909000.npy', 'split': 'test'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19824/19824 [00:02<00:00, 8304.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[1.9113459920044988, 1.1814273169729859, 1.2722794610017445, 1.2290884499961976, 2.4898757610062603]\n",
      "Average time 1.6168 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_split = dataset.get_split(\"test\")\n",
    "\n",
    "vis_points = []\n",
    "times = []\n",
    "\n",
    "# for idx in range(len(test_split)):\n",
    "for idx in range(5):\n",
    "\n",
    "    st = time.perf_counter()\n",
    "    attr = test_split.get_attr(idx)\n",
    "    data = test_split.get_data(idx)\n",
    "\n",
    "    print(attr)\n",
    "    results = pipeline.run_inference(data)\n",
    "\n",
    "    pred = (results[\"predict_labels\"]).astype(np.int32)\n",
    "\n",
    "    label = data[\"label\"]\n",
    "    pts = data[\"point\"]\n",
    "\n",
    "    vis_d = {\n",
    "        \"name\": attr[\"name\"],\n",
    "        \"points\": pts,\n",
    "        \"labels\": label,\n",
    "        \"pred\": pred,\n",
    "    }\n",
    "\n",
    "    vis_points.append(vis_d)\n",
    "    et = time.perf_counter()\n",
    "    times.append(et - st)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(times)\n",
    "print(f\"Average time {np.mean(times):0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "behavioral-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Unlabeled', 1: 'Floor', 2: 'Wall', 3: 'Robot', 4: 'Human', 5: 'AGV'}\n"
     ]
    }
   ],
   "source": [
    "v = ml3d.vis.Visualizer()\n",
    "\n",
    "lut = ml3d.vis.LabelLUT()\n",
    "\n",
    "# pprint.pprint(colors)\n",
    "\n",
    "label_names = dataset.get_label_to_names()\n",
    "pprint.pprint(label_names)\n",
    "\n",
    "for (c, cv), (l, lv) in zip(colors.items(), label_names.items()):\n",
    "    lut.add_label(lv, l, cv)\n",
    "\n",
    "# for key, val in dataset.label_to_names.items():\n",
    "#     lut.add_label(val, key)\n",
    "\n",
    "v.set_lut(\"labels\", lut)\n",
    "v.set_lut(\"pred\", lut)\n",
    "\n",
    "v.visualize(vis_points, lut, width=2600, height=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique, counts = np.unique(data[\"label\"], return_counts=True)\n",
    "# print(np.asarray((unique, counts)))\n",
    "    \n",
    "test_split = dataset.get_split(\"test\")\n",
    "\n",
    "attr = test_split.get_attr(0)\n",
    "data = test_split.get_data(0)\n",
    "\n",
    "print(attr)\n",
    "results = pipeline.run_inference(data)\n",
    "\n",
    "pred = (results[\"predict_labels\"]).astype(np.int32)\n",
    "\n",
    "label = data['label']\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
